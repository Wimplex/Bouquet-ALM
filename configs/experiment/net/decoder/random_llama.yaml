_target_: transformers.AutoModelForCausalLM.from_config
config:
  _target_: transformers.LlamaConfig
  hidden_size: 256
  intermediate_size: 704
  num_attention_heads: 8
  num_hidden_layers: 2
  num_key_value_heads: 8